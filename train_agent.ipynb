{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Anagram Solver RL Training\n",
        "\n",
        "Train LLM agent to solve anagram puzzles using GRPO with proper data preparation.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PollyLeo6/Anagram-Solver/blob/main/train_agent.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "import re\n",
        "\n",
        "# Fix random seeds\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if not os.path.exists('anagram_game.py'):\n",
        "    print('ðŸ“¥ Cloning repository...')\n",
        "    !git clone https://github.com/PollyLeo6/Anagram-Solver.git\n",
        "    %cd Anagram-Solver\n",
        "    print('âœ… Repository cloned!')\n",
        "\n",
        "!pip install torch transformers datasets accelerate peft trl unsloth matplotlib\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from transformers import TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "from datasets import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from anagram_game import AnagramSolverEnv\n",
        "from utils import create_english_dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# System prompt for anagram solving\n",
        "SYSTEM_PROMPT = \"\"\"You are an expert anagram solver. Your task is to unscramble letters to form valid English words.\n",
        "\n",
        "Rules:\n",
        "1. Use each letter exactly once\n",
        "2. Form valid English words only\n",
        "3. Respond in JSON format: {\"solutions\": [\"word1\", \"word2\", ...]}\n",
        "4. Order words as they appear in the anagram list\n",
        "\n",
        "Be accurate and follow the format exactly.\"\"\"\n",
        "\n",
        "def extract_json_answer(text: str) -> str:\n",
        "    \"\"\"Extract JSON answer from response\"\"\"\n",
        "    try:\n",
        "        # Find JSON in text\n",
        "        start = text.find('{')\n",
        "        end = text.rfind('}') + 1\n",
        "        if start != -1 and end > start:\n",
        "            json_str = text[start:end]\n",
        "            parsed = json.loads(json_str)\n",
        "            return json_str\n",
        "        return text.strip()\n",
        "    except:\n",
        "        return text.strip()\n",
        "\n",
        "def get_anagram_dataset(env, num_samples=71, difficulties=range(1, 8)):\n",
        "    \"\"\"Generate anagram dataset in HuggingFace format\"\"\"\n",
        "    data = []\n",
        "    for difficulty in difficulties:\n",
        "        tasks = env.generate(num_of_questions=num_samples, difficulty=difficulty)\n",
        "        for task in tasks:\n",
        "            data.append({\n",
        "                'prompt': [\n",
        "                    {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "                    {'role': 'user', 'content': task.question}\n",
        "                ],\n",
        "                'answer': task.answer,\n",
        "                'difficulty': difficulty,\n",
        "                'metadata': task.metadata\n",
        "            })\n",
        "    return Dataset.from_list(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dictionary and create environments\n",
        "create_english_dictionary()\n",
        "with open('dictionary.txt', 'r', encoding='utf-8') as f:\n",
        "    full_dictionary = [line.strip() for line in f.readlines()]\n",
        "\n",
        "random.shuffle(full_dictionary)\n",
        "split_idx = int(0.7 * len(full_dictionary))\n",
        "train_words = full_dictionary[:split_idx]\n",
        "test_words = full_dictionary[split_idx:]\n",
        "\n",
        "print(f\"Dictionary split - Train: {len(train_words)}, Test: {len(test_words)}\")\n",
        "\n",
        "# Create custom environments\n",
        "class TrainAnagramEnv(AnagramSolverEnv):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dictionary = set(train_words)\n",
        "        \n",
        "class TestAnagramEnv(AnagramSolverEnv):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.dictionary = set(test_words)\n",
        "\n",
        "train_env = TrainAnagramEnv()\n",
        "test_env = TestAnagramEnv()\n",
        "\n",
        "# Generate datasets\n",
        "train_dataset = get_anagram_dataset(train_env, num_samples=71, difficulties=range(1, 8))\n",
        "print(f\"Generated {len(train_dataset)} training examples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reward Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function for correct anagram solutions\"\"\"\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    q = prompts[0][-1]['content']\n",
        "    extracted_responses = [extract_json_answer(r) for r in responses]\n",
        "    \n",
        "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
        "    \n",
        "    rewards = []\n",
        "    for r, a in zip(extracted_responses, answer):\n",
        "        try:\n",
        "            # Parse both as JSON and compare\n",
        "            r_json = json.loads(r) if isinstance(r, str) else r\n",
        "            a_json = json.loads(a) if isinstance(a, str) else a\n",
        "            \n",
        "            if r_json == a_json:\n",
        "                rewards.append(2.0)\n",
        "            else:\n",
        "                rewards.append(0.0)\n",
        "        except:\n",
        "            rewards.append(0.0)\n",
        "    \n",
        "    return rewards\n",
        "\n",
        "def format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function for JSON format compliance\"\"\"\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    rewards = []\n",
        "    \n",
        "    for response in responses:\n",
        "        try:\n",
        "            extracted = extract_json_answer(response)\n",
        "            parsed = json.loads(extracted)\n",
        "            if 'solutions' in parsed and isinstance(parsed['solutions'], list):\n",
        "                rewards.append(0.5)\n",
        "            else:\n",
        "                rewards.append(0.0)\n",
        "        except:\n",
        "            rewards.append(0.0)\n",
        "    \n",
        "    return rewards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/Qwen2.5-1.5B-Instruct\",\n",
        "    max_seq_length=2048,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                   \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        ")\n",
        "\n",
        "print(\"Model loaded with LoRA adapters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SFT Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Format dataset for SFT\n",
        "def format_conversation(example):\n",
        "    formatted = tokenizer.apply_chat_template(\n",
        "        example['prompt'] + [{'role': 'assistant', 'content': example['answer']}],\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=False\n",
        "    )\n",
        "    return {\"text\": formatted}\n",
        "\n",
        "formatted_dataset = train_dataset.map(format_conversation)\n",
        "print(f\"Formatted dataset size: {len(formatted_dataset)}\")\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./anagram_sft\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=5e-5,\n",
        "    warmup_steps=50,\n",
        "    logging_steps=10,\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False,\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=formatted_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=2048,\n",
        ")\n",
        "\n",
        "print(\"Starting SFT training...\")\n",
        "trainer.train()\n",
        "print(\"SFT training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, tokenizer, env, difficulty=5, num_samples=20):\n",
        "    \"\"\"Evaluate model on given environment\"\"\"\n",
        "    correct_count = 0\n",
        "    test_tasks = env.generate(num_of_questions=num_samples, difficulty=difficulty)\n",
        "    \n",
        "    for task in test_tasks:\n",
        "        try:\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": task.question}\n",
        "            ]\n",
        "            \n",
        "            input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "            inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                outputs = model.generate(**inputs, max_new_tokens=100, temperature=0.7, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
        "            \n",
        "            response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "            result = env.verifier.verify(task, response)\n",
        "            if result:\n",
        "                correct_count += 1\n",
        "        except Exception:\n",
        "            continue\n",
        "    \n",
        "    return correct_count / num_samples\n",
        "\n",
        "# Evaluate on both train and test environments\n",
        "print(\"Evaluating model...\")\n",
        "train_acc = evaluate_model(model, tokenizer, train_env, difficulty=5)\n",
        "test_acc = evaluate_model(model, tokenizer, test_env, difficulty=5)\n",
        "test_hard = evaluate_model(model, tokenizer, test_env, difficulty=8)\n",
        "\n",
        "print(f\"Results:\")\n",
        "print(f\"Train accuracy: {train_acc:.3f}\")\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")\n",
        "print(f\"Test hard accuracy: {test_hard:.3f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}